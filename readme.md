# RAG Chatbot

## Table of Contents
- [Project Overview](#project-overview)
- [Features](#features)
- [Installation](#installation)
- [Technologies Used](#technologies-used)
- [License](#license)

## Project Overview
The RAG Chatbot is a Retrieval-Augmented Generation (RAG) based chatbot designed to answer queries by leveraging both retrieval and generation techniques. It utilizes a document database and a language model to provide accurate and contextually relevant responses. This project is built using LangChain, FAISS, and Hugging Face Transformers.

## Features
- **Document Ingestion:** Load and process documents from various formats (e.g., PDFs).
- **Vector Store:** Efficient document retrieval using FAISS for similarity search.
- **Language Model Integration:** Answer generation using a Hugging Face transformer model.
- **Chainlit Interface:** A web-based UI for interacting with the chatbot.

## Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package installer)
- A virtual environment tool (e.g., `venv`, `virtualenv`)

### Steps
1. **Clone the Repository:**
   ```bash
   git clone https://github.com/yourusername/rag_chatbot.git
   cd rag_chatbot

2. **Install the dependencies in a virtual environment:**
- Make sure the correct versions are downloaded. Be vary that the code might work only with a older version of certain packages as this project was completed a while back.

3. **RAG Data**
- Upload the necessary files you want the model to intake as context into the folder named 'data'.

4. **Custom prompt**
- Set the custom prompt that will provide a contextual guidance for the model. It will enchance the response that you will receive from the model. The same can be altered with altering the "CUSTOM_PROMPT_TEMPLATE" object in the 'chatbot.py' file.

4. **Model**
- In this code, the model 'TheBloke/Llama-2-7B-Chat-GGUF' from Hugging face has been used, if you wish to use any other model, the model variable can be altered with the appropriate naming.

6. **Running the Scripts**
- First it's essential to prepare the data for the chatbot using the syntax:- 
    ```bash
    ingest.py
This prepares the data that your chatbot or retrieval system will use to function. In ensures the embeddings are created and data is indexed.

- Then run the following syntax to run the chatbot. 
    ```bash
    chainlit chatbot.py
This makes the chatbot service operational, allowing you to interact with it. It used the indexed data and embeddings generated by 'ingest.py'. It handles user interactions.

### Technologies Used
- LangChain: For building the retrieval-augmented generation chain.
- FAISS: Facebook's library for efficient similarity search and clustering of dense vectors.
- Hugging Face Transformers: For embedding and language model-based answer generation.
- Chainlit: A lightweight framework to create web interfaces for LLM-based applications.
- FastAPI: For creating the backend REST API (if applicable).
- Python: The core language used in this project.

### License
- This project is licensed under the MIT License - see the LICENSE file for details.